\relax 
\citation{coocc}
\@writefile{toc}{\contentsline {section}{\numberline {1}Network Building}{1}}
\@writefile{toc}{\contentsline {subsection}{\numberline {1.1}Co-occurrence construction}{1}}
\@writefile{toc}{\contentsline {subsection}{\numberline {1.2}Correlation construction}{2}}
\citation{coocc}
\@writefile{toc}{\contentsline {subsection}{\numberline {1.3}Significance of the network}{3}}
\citation{PhysRevE.70.066111}
\citation{PhysRevE.70.056131}
\citation{vonLuxburg2007}
\@writefile{lof}{\contentsline {figure}{\numberline {1}{\ignorespaces The result of Monte-Carlo estimation of the likelihood of various network statistitics, as well as the number of edges and mean degree. The networks were made from correlations using randomly drawn subsets of the data of increasing size, from 1 sample to all 60 samples. For each network, 1000 random trials were generated according to the above null model in order to estimate likelihood of statistics.\relax }}{4}}
\providecommand*\caption@xref[2]{\@setref\relax\@undefined{#1}}
\newlabel{montecarlos}{{1}{4}}
\newlabel{montecarlos@cref}{{[figure][1][]1}{4}}
\@writefile{toc}{\contentsline {section}{\numberline {2}Network Analysis}{4}}
\@writefile{toc}{\contentsline {section}{\numberline {3}Using the network to analyze a sample}{4}}
\citation{machine_learning}
\@writefile{toc}{\contentsline {subsection}{\numberline {3.1}Determining $\psi _c$}{5}}
\@writefile{lof}{\contentsline {figure}{\numberline {2}{\ignorespaces A small network example\relax }}{6}}
\newlabel{toy_network}{{2}{6}}
\newlabel{toy_network@cref}{{[figure][2][]2}{6}}
\citation{machine_learning}
\@writefile{toc}{\contentsline {subsection}{\numberline {3.2}Comparing configurations without specifying $\psi $}{7}}
\@writefile{toc}{\contentsline {subsection}{\numberline {3.3}Diffusion based method.}{8}}
\citation{vonLuxburg2007}
\citation{Anderson2010}
\newlabel{initalCond}{{1}{9}}
\newlabel{initalCond@cref}{{[method][1][]1}{9}}
\newlabel{first_wins}{{2}{9}}
\newlabel{first_wins@cref}{{[equation][2][]2}{9}}
\newlabel{boundarVal}{{2}{10}}
\newlabel{boundarVal@cref}{{[method][2][]2}{10}}
\newlabel{forcing}{{3}{11}}
\newlabel{forcing@cref}{{[method][3][]3}{11}}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {3.3.1}Tests of these methods}{11}}
\@writefile{lof}{\contentsline {figure}{\numberline {3}{\ignorespaces Diffusion is equivalent to the Kolmogorov forward equations for the above system.\relax }}{12}}
\newlabel{kfor}{{3}{12}}
\newlabel{kfor@cref}{{[figure][3][]3}{12}}
\@writefile{lof}{\contentsline {figure}{\numberline {4}{\ignorespaces Test networks. Gray nodes were ``unknown", blue nodes ``off", and red ``on".\relax }}{12}}
\newlabel{tests}{{4}{12}}
\newlabel{tests@cref}{{[figure][4][]4}{12}}
\@writefile{lot}{\contentsline {table}{\numberline {1}{\ignorespaces Results of ranking nodes by liklihood of being ``on" by the three above methods\relax }}{12}}
\newlabel{rankres}{{1}{12}}
\newlabel{rankres@cref}{{[table][1][]1}{12}}
\@writefile{lof}{\contentsline {figure}{\numberline {5}{\ignorespaces Result of diffusion methods. Edge color represents the shared sample type of the nodes (i.e. samply type the taxa was found most often in), with gray indicating different types.\relax }}{13}}
\newlabel{diffusion_sample}{{5}{13}}
\newlabel{diffusion_sample@cref}{{[figure][5][]5}{13}}
\@writefile{toc}{\contentsline {subsection}{\numberline {3.4}Read production based analysis}{14}}
\citation{Vishwanathan}
\@writefile{toc}{\contentsline {section}{\numberline {4}Comparison of Networks}{15}}
\@writefile{toc}{\contentsline {subsection}{\numberline {4.1}Matching samples to networks}{16}}
\@writefile{lof}{\contentsline {figure}{\numberline {6}{\ignorespaces Test networks. \relax }}{17}}
\newlabel{more_tests}{{6}{17}}
\newlabel{more_tests@cref}{{[figure][6][]6}{17}}
\@writefile{lof}{\contentsline {figure}{\numberline {7}{\ignorespaces Results of sample assignment: $u_1$ cannot be decided, $u_2$ is assigned to network $A_1$, and $u_3$ is assigned to network $A_2$.\relax }}{17}}
\newlabel{tiny_res}{{7}{17}}
\newlabel{tiny_res@cref}{{[figure][7][]7}{17}}
\@writefile{lof}{\contentsline {figure}{\numberline {8}{\ignorespaces A training data column fits the network better than a randomly generated sample.\relax }}{18}}
\newlabel{full_assign}{{8}{18}}
\newlabel{full_assign@cref}{{[figure][8][]8}{18}}
\bibstyle{plain}
\bibdata{../../../summer17}
\bibcite{Anderson2010}{1}
\bibcite{PhysRevE.70.066111}{2}
\bibcite{machine_learning}{3}
\bibcite{coocc}{4}
\bibcite{PhysRevE.70.056131}{5}
\bibcite{Vishwanathan}{6}
\bibcite{vonLuxburg2007}{7}
