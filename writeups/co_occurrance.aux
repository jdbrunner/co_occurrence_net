\relax 
\citation{coocc}
\@writefile{toc}{\contentsline {section}{\numberline {1}Network Building}{1}}
\@writefile{toc}{\contentsline {subsection}{\numberline {1.1}An alternative correlation construction}{2}}
\citation{PhysRevE.70.066111}
\citation{PhysRevE.70.056131}
\citation{vonLuxburg2007}
\@writefile{toc}{\contentsline {subsection}{\numberline {1.2}Significance of network}{3}}
\@writefile{toc}{\contentsline {section}{\numberline {2}Network Analysis}{3}}
\@writefile{toc}{\contentsline {section}{\numberline {3}Using the network to analyze a sample}{3}}
\citation{machine_learning}
\@writefile{toc}{\contentsline {subsection}{\numberline {3.1}Determining $\psi _c$}{4}}
\@writefile{lof}{\contentsline {figure}{\numberline {1}{\ignorespaces A small network example\relax }}{5}}
\providecommand*\caption@xref[2]{\@setref\relax\@undefined{#1}}
\newlabel{toy_network}{{1}{5}}
\newlabel{toy_network@cref}{{[figure][1][]1}{5}}
\citation{machine_learning}
\@writefile{toc}{\contentsline {subsection}{\numberline {3.2}Comparing configurations without specifying $\psi $}{6}}
\@writefile{toc}{\contentsline {subsection}{\numberline {3.3}Diffusion based method.}{7}}
\citation{vonLuxburg2007}
\citation{Anderson2010}
\newlabel{initalCond}{{1}{8}}
\newlabel{initalCond@cref}{{[method][1][]1}{8}}
\newlabel{first_wins}{{2}{8}}
\newlabel{first_wins@cref}{{[equation][2][]2}{8}}
\newlabel{boundarVal}{{2}{9}}
\newlabel{boundarVal@cref}{{[method][2][]2}{9}}
\newlabel{forcing}{{3}{10}}
\newlabel{forcing@cref}{{[method][3][]3}{10}}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {3.3.1}Tests of these methods}{10}}
\@writefile{lof}{\contentsline {figure}{\numberline {2}{\ignorespaces Diffusion is equivalent to the Kolmogorov forward equations for the above system.\relax }}{11}}
\newlabel{kfor}{{2}{11}}
\newlabel{kfor@cref}{{[figure][2][]2}{11}}
\@writefile{lof}{\contentsline {figure}{\numberline {3}{\ignorespaces Test networks. Gray nodes were ``unknown", blue nodes ``off", and red ``on".\relax }}{11}}
\newlabel{tests}{{3}{11}}
\newlabel{tests@cref}{{[figure][3][]3}{11}}
\@writefile{lot}{\contentsline {table}{\numberline {1}{\ignorespaces Results of ranking nodes by liklihood of being ``on" by the three above methods\relax }}{11}}
\newlabel{rankres}{{1}{11}}
\newlabel{rankres@cref}{{[table][1][]1}{11}}
\@writefile{lof}{\contentsline {figure}{\numberline {4}{\ignorespaces Result of diffusion methods. Edge color represents the shared sample type of the nodes (i.e. samply type the taxa was found most often in), with gray indicating different types.\relax }}{12}}
\newlabel{diffusion_sample}{{4}{12}}
\newlabel{diffusion_sample@cref}{{[figure][4][]4}{12}}
\@writefile{toc}{\contentsline {subsection}{\numberline {3.4}Read production based analysis}{13}}
\citation{Vishwanathan}
\@writefile{toc}{\contentsline {section}{\numberline {4}Comparison of Networks}{14}}
\@writefile{toc}{\contentsline {subsection}{\numberline {4.1}Matching samples to networks}{15}}
\@writefile{lof}{\contentsline {figure}{\numberline {5}{\ignorespaces Test networks. \relax }}{16}}
\newlabel{more_tests}{{5}{16}}
\newlabel{more_tests@cref}{{[figure][5][]5}{16}}
\@writefile{lof}{\contentsline {figure}{\numberline {6}{\ignorespaces Results of sample assignment: $u_1$ cannot be decided, $u_2$ is assigned to network $A_1$, and $u_3$ is assigned to network $A_2$.\relax }}{16}}
\newlabel{tiny_res}{{6}{16}}
\newlabel{tiny_res@cref}{{[figure][6][]6}{16}}
\@writefile{lof}{\contentsline {figure}{\numberline {7}{\ignorespaces A training data column fits the network better than a randomly generated sample.\relax }}{17}}
\newlabel{full_assign}{{7}{17}}
\newlabel{full_assign@cref}{{[figure][7][]7}{17}}
\bibstyle{plain}
\bibdata{../../../summer17}
\bibcite{Anderson2010}{1}
\bibcite{PhysRevE.70.066111}{2}
\bibcite{machine_learning}{3}
\bibcite{coocc}{4}
\bibcite{PhysRevE.70.056131}{5}
\bibcite{Vishwanathan}{6}
\bibcite{vonLuxburg2007}{7}
